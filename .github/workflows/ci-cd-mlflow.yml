name: CI + CD (DVC data, MLflow model â†’ GAR + GKE)

on:
  push:
    branches: [ main, week6 ]
  pull_request:
    branches: [ main, week6 ]

permissions:
  contents: write
  pull-requests: write
  id-token: write

jobs:
  sanity:
    name: Sanity (DVC + MLflow) + CML
    runs-on: ubuntu-latest
    env:
      MODEL_NAME: Iris-Classifier
      DATA_CSV_PATH: data/data.csv
      TARGET_COL: species
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      # --- CD settings ---
      GAR_REGION: us-central1
      GAR_REPO: my-repo
      IMAGE_NAME: iris-api
      CLUSTER_NAME: gke-iris-cluster
      CLUSTER_LOCATION: us-central1
      NAMESPACE: default

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Set up CML
        uses: iterative/setup-cml@v2

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/req.txt') }}
          restore-keys: pip-${{ runner.os }}-

      - name: Install system deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y git-lfs
          git lfs install

      - name: Auth to GCP (for DVC + GAR + GKE)
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Install Python deps (repo CI)
        run: |
          python -m pip install --upgrade pip
          pip install -r req.txt

      - name: DVC pull data from GCS
        run: dvc pull -v

      - name: Resolve MLflow model URI (latest version)
        id: resolve
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MODEL_NAME: ${{ env.MODEL_NAME }}
        run: |
          python - <<'PY'
          import os, sys, mlflow
          from mlflow.tracking import MlflowClient
          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          name = os.environ["MODEL_NAME"]
          client = MlflowClient()

          # ensure model exists
          try:
              client.get_registered_model(name)
          except Exception:
              print(f"::error::Registered model '{name}' not found at {os.environ['MLFLOW_TRACKING_URI']}.")
              sys.exit(1)

          versions = client.search_model_versions(f"name='{name}'")
          if not versions:
              print(f"::error::Model '{name}' has no versions.")
              sys.exit(1)

          latest = max(versions, key=lambda v: int(v.version))
          uri = f"models:/{name}/{latest.version}"
          print(f"Resolved MODEL_URI: {uri}")
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"model_uri={uri}\n")
          PY

      - name: Evaluate model on CSV
        env:
          MODEL_URI: ${{ steps.resolve.outputs.model_uri }}
          DATA_CSV_PATH: ${{ env.DATA_CSV_PATH }}
          TARGET_COL: ${{ env.TARGET_COL }}
        run: |
          python - <<'PY'
          import os, json, pandas as pd, mlflow
          data_csv = os.environ["DATA_CSV_PATH"]
          target = os.environ["TARGET_COL"]
          model_uri = os.environ["MODEL_URI"]

          df = pd.read_csv(data_csv)
          X = df.drop(columns=[target])
          y = df[target]

          model = mlflow.pyfunc.load_model(model_uri)
          y_pred = model.predict(X)
          acc = float((y_pred == y).mean())

          report = {"model_uri": model_uri, "rows": int(len(df)), "accuracy": acc}
          print(json.dumps(report, indent=2))
          with open("sanity.json", "w") as f:
            json.dump(report, f, indent=2)
          PY

      - name: CML comment (sanity report)
        if: ${{ github.event_name == 'pull_request' }}
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo '### Sanity Check (DVC data + MLflow model)' > report.md
          echo '' >> report.md
          echo '**Model URI:** `${{ steps.resolve.outputs.model_uri }}`' >> report.md
          echo '' >> report.md
          echo '\`\`\`json' >> report.md
          cat sanity.json >> report.md
          echo '\`\`\`' >> report.md
          cml comment create --publish report.md

      # -------------------- CD: only on push to main or week6 --------------------
      - name: Configure Docker for Artifact Registry
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        run: gcloud auth configure-docker $GAR_REGION-docker.pkg.dev -q

      - name: Build & push Docker image to GAR (fastapi/)
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        env:
          IMG_SHA: ${{ github.sha }}
        run: |
          echo "Listing repo root"; ls -la
          echo "Listing fastapi dir"; ls -la fastapi

          # Use classic docker builder to avoid buildx context confusion
          DOCKER_BUILDKIT=0 docker build \
            -f fastapi/Dockerfile \
            -t ${GAR_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPO}/${IMAGE_NAME}:${IMG_SHA} \
            -t ${GAR_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPO}/${IMAGE_NAME}:latest \
            fastapi

          docker push ${GAR_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPO}/${IMAGE_NAME}:${IMG_SHA}
          docker push ${GAR_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPO}/${IMAGE_NAME}:latest

      - name: Get GKE credentials
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ env.CLUSTER_NAME }}
          location: ${{ env.CLUSTER_LOCATION }}
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Apply manifests
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        run: |
          kubectl apply -n ${NAMESPACE} -f k8s/deployment.yaml
          kubectl apply -n ${NAMESPACE} -f k8s/service.yaml

      - name: Update image to latest SHA
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        env:
          IMG_SHA: ${{ github.sha }}
        run: |
          kubectl set image deployment/iris-api \
            iris-api=${GAR_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPO}/${IMAGE_NAME}:${IMG_SHA} \
            -n ${NAMESPACE}
          kubectl rollout status deployment/iris-api -n ${NAMESPACE} --timeout=180s

      - name: In-cluster smoke test (GET /)
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/week6')
        run: |
          # curl inside the cluster via Service DNS (uses default port 80->containerPort)
          kubectl run smoke --rm -i --restart=Never -n ${NAMESPACE} \
            --image=curlimages/curl -- \
            -sS http://iris-api.${NAMESPACE}.svc.cluster.local/ \
            | tee smoke_root.txt
          grep -q 'Welcome to the Iris Classifier API' smoke_root.txt
