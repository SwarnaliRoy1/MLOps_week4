name: Sanity Test (DVC data + MLflow model)

on:
  push:
    branches: [ dev, main ]
  pull_request:
    branches: [ dev, main ]

permissions:
  contents: write
  pull-requests: write

jobs:
  sanity:
    runs-on: ubuntu-latest
    env:
      # ---- project-specific defaults ----
      MODEL_NAME: Iris-Classifier
      DATA_CSV_PATH: data/data.csv
      TARGET_COL: species
      # expose the secret to env so we can check it in `if:`
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      # -----------------------------------

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/req.txt') }}
          restore-keys: pip-${{ runner.os }}-

      - name: Install system deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y git-lfs
          git lfs install

      - name: Auth to GCP (for DVC GCS remote)
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud (optional)
        if: ${{ env.GCP_PROJECT_ID != '' }}
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r req.txt

      - name: DVC pull data from GCS
        run: dvc pull -v

      # Keep the resolver simple and fast: prefer Production. If not present,
      # only then list versions and take the highest version number.
      - name: Resolve MLflow model URI
        id: resolve
        env:
          MODEL_NAME: ${{ env.MODEL_NAME }}
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
        run: |
          python - <<'PY'
          import os, sys, json
          import mlflow
          from mlflow.tracking import MlflowClient

          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          name = os.environ["MODEL_NAME"]
          client = MlflowClient()

          # Try Production directly with a cheap query
          prod = client.get_latest_versions(name, stages=["Production"])
          if prod:
            uri = f"models:/{name}/Production"
          else:
            # Fallback: take the highest version only if we must
            versions = client.search_model_versions(f"name='{name}'")
            if not versions:
              print(f"::error::No registered versions for model '{name}'.")
              sys.exit(1)
            latest = max(versions, key=lambda v: int(v.version))
            uri = f"models:/{name}/{latest.version}"

          # Emit output
          print(f"Resolved MODEL_URI: {uri}")
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"model_uri={uri}\n")
          PY

      # Super-light evaluator inline (no repo changes needed).
      # Loads the model and prints a small JSON summary to stdout.
      - name: Evaluate model on CSV
        env:
          MODEL_URI: ${{ steps.resolve.outputs.model_uri }}
          DATA_CSV_PATH: ${{ env.DATA_CSV_PATH }}
          TARGET_COL: ${{ env.TARGET_COL }}
        run: |
          python - <<'PY'
          import os, json
          import pandas as pd
          import mlflow

          data_csv = os.environ["DATA_CSV_PATH"]
          target = os.environ["TARGET_COL"]
          model_uri = os.environ["MODEL_URI"]

          df = pd.read_csv(data_csv)
          X = df.drop(columns=[target])
          y = df[target]

          model = mlflow.pyfunc.load_model(model_uri)
          # Try predict; if estimator has predict_proba we ignore it for simplicity
          y_pred = model.predict(X)

          # simple accuracy (works for Iris)
          acc = (y_pred == y).mean()
          report = {
            "model_uri": model_uri,
            "rows": int(len(df)),
            "accuracy": float(acc)
          }
          print(json.dumps(report, indent=2))
          # also persist for PR comment step
          with open("sanity.json", "w") as f:
            json.dump(report, f, indent=2)
          PY

      - name: Post report as PR comment (CML)
        if: ${{ github.event_name == 'pull_request' }}
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo '### Sanity Check (DVC data + MLflow model)' > report.md
          echo '' >> report.md
          echo '**Model URI:** `${{ steps.resolve.outputs.model_uri }}`' >> report.md
          echo '' >> report.md
          echo '\`\`\`json' >> report.md
          cat sanity.json >> report.md
          echo '\`\`\`' >> report.md
          npx cml comment report.md
